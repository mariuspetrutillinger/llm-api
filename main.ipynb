{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import onnxruntime_genai as og\n",
    "import numpy as np\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokens.json\") as f:\n",
    "    tokens = json.load(f)\n",
    "\n",
    "hf_token = tokens[\"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_options = {}\n",
    "search_options['max_length'] = 4096\n",
    "\n",
    "chat_template = '<|user|>\\n{input} <|end|>\\n<|assistant|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_dir = '../Ofertetest/'\n",
    "\n",
    "model_inputs = []\n",
    "\n",
    "for filename in os.listdir(docx_dir):\n",
    "    if filename.endswith('.docx'):\n",
    "        docx_file = docx_dir + filename\n",
    "        text = read_docx(docx_file)\n",
    "        text = preprocess_text(text)\n",
    "        model_inputs.append(text)\n",
    "\n",
    "with open(\"model_inputs.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in model_inputs:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = og.Model('./myenv/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4')\n",
    "tokenizer = og.Tokenizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: "
     ]
    }
   ],
   "source": [
    "text = input(\"Input: \")\n",
    "if not text:\n",
    "   print(\"Error, input cannot be empty\")\n",
    "   exit\n",
    "\n",
    "prompt = chat_template.format(input=text)\n",
    "\n",
    "input_tokens = tokenizer.encode(prompt)\n",
    "\n",
    "params = og.GeneratorParams(model)\n",
    "params.set_search_options(**search_options)\n",
    "params.input_ids = input_tokens\n",
    "generator = og.Generator(model, params)\n",
    "\n",
    "print(\"Output: \", end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \"Acum, voi cere o oferta de dezvoltare unei aplicatii în stil global. Acest proiect este un moment esențial pentru echipa noastră și pentru echipa clientilor. Am asigurat că este corect și eficient, și voi oferi o oportunitate foarte bună pentru echipa clientilor. Am pus foarte mult eserciti în prezent, și voi continua adevărat a veni cu o soluție eficientă pentru echipa clientilor. Am asigurat că este o oportunitate foarte bună pentru echipa clientilor. Am pus foarte mult eserciti în prezent, și voi continua adevărat a veni cu o soluție eficientă pentru echipa clientilor. Am asigurat că este o oportunitate foarte bună pentru echipa clientilor. Am pus foarte mult eserciti în prezent, și voi continua adevărat a veni cu o soluție eficientă pentru echipa clientilor. Am asigurat că este o oportunitate foarte bună pentru echipa clientilor. Am pus foarte mult eserciti în prezent, și vo  --control+c pressed, aborting generation--\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   while not generator.is_done():\n",
    "     generator.compute_logits()\n",
    "     generator.generate_next_token()\n",
    "\n",
    "     new_token = generator.get_next_tokens()[0]\n",
    "     print(tokenizer_stream.decode(new_token), end='', flush=True)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"  --control+c pressed, aborting generation--\")\n",
    "\n",
    "print()\n",
    "del generator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
