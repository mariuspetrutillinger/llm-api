{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import onnxruntime_genai as og\n",
    "import numpy as np\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokens.json\") as f:\n",
    "    tokens = json.load(f)\n",
    "\n",
    "hf_token = tokens[\"token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_options = {}\n",
    "search_options['max_length'] = 4096\n",
    "\n",
    "chat_template = '<|user|>\\n{input} <|end|>\\n<|assistant|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_dir = '../Ofertetest/'\n",
    "\n",
    "model_inputs = []\n",
    "\n",
    "for filename in os.listdir(docx_dir):\n",
    "    if filename.endswith('.docx'):\n",
    "        docx_file = docx_dir + filename\n",
    "        text = read_docx(docx_file)\n",
    "        text = preprocess_text(text)\n",
    "        model_inputs.append(text)\n",
    "\n",
    "with open(\"model_inputs.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in model_inputs:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = og.Model('./myenv/cpu_and_mobile/cpu-int4-rtn-block-32-acc-level-4')\n",
    "tokenizer = og.Tokenizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: "
     ]
    }
   ],
   "source": [
    "text = input(\"Input: \")\n",
    "if not text:\n",
    "   print(\"Error, input cannot be empty\")\n",
    "   exit\n",
    "\n",
    "prompt = chat_template.format(input=text)\n",
    "\n",
    "input_tokens = tokenizer.encode(prompt)\n",
    "\n",
    "params = og.GeneratorParams(model)\n",
    "params.set_search_options(**search_options)\n",
    "params.input_ids = input_tokens\n",
    "generator = og.Generator(model, params)\n",
    "\n",
    "print(\"Output: \", end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      " e.\n",
      ".\n",
      " \n",
      ".\n",
      ".\n",
      " le.\n",
      " e.\n",
      " \n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      " iare.\n",
      " re.\n",
      " iare.\n",
      " \n",
      ".\n",
      " e lucu.\n",
      " \n",
      " re, e luc.\n",
      "ap.\n",
      " \n",
      " \n",
      " \n",
      " leg cu a n iare. iare. iare. \n",
      "gh. iare. \n",
      "ap sale. 2. \n",
      " \n",
      " \n",
      "  in im formos. 1 leg re. \n",
      "prim. \n",
      "  la, luc cu. iare. \n",
      "  or gh or ac la re. iare.  la \n",
      " \n",
      "  la. \n",
      " \n",
      "  È™i. \n",
      "  in. \n",
      "  a. \n",
      " \n",
      "  in 1. iare. iare. 1.  la 1. iare. ia. 2. \n",
      "  in o leg or o sale. \n",
      " \n",
      " \n",
      "  in \n",
      "  a iare.  legare. iare. iare. iare. iare.  in im form sau a re. iare. iare."
     ]
    }
   ],
   "source": [
    "try:\n",
    "   while not generator.is_done():\n",
    "     generator.compute_logits()\n",
    "     generator.generate_next_token()\n",
    "\n",
    "     new_token = generator.get_next_tokens()[0]\n",
    "     print(tokenizer_stream.decode(new_token), end='', flush=True)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"  --control+c pressed, aborting generation--\")\n",
    "\n",
    "print()\n",
    "del generator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
